{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JxrcJu64gGdz"
   },
   "outputs": [],
   "source": [
    "#uses pandas and then convert to list/dict\n",
    "import pandas as pd \n",
    "import string\n",
    "from string import punctuation\n",
    "import re\n",
    "import emoji\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import itertools\n",
    "import time\n",
    "import contractions\n",
    "import pickle\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwBf8mpmhML7"
   },
   "outputs": [],
   "source": [
    "data_folder = 'data/'\n",
    "#glove_folder = 'E:/rajiur/workspace/nlp/data/'\n",
    "glove_folder = 'D:/workspace/nlp/glove/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRYDvygXhYi8"
   },
   "outputs": [],
   "source": [
    "dfdevraw = pd.read_csv(data_folder+\"dev.csv\", encoding='latin') \n",
    "dftrainraw =  pd.read_csv(data_folder+\"train.csv\", encoding='latin') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "MR7z3365hixq",
    "outputId": "ae16d707-9538-40db-9434-2b38e65cfc46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook_corpus_msr_451811</td>\n",
       "      <td>The quality of re made now makes me think it i...</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook_corpus_msr_334368</td>\n",
       "      <td>@siva \\rHow is ur mother???\\rHow is ur wife???...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook_corpus_msr_331195</td>\n",
       "      <td>Also see ....hw ur RSS activist caught in Burk...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook_corpus_msr_403402</td>\n",
       "      <td>On the death of 2 jawans in LOC CROSS FIRING\\r...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook_corpus_msr_379239</td>\n",
       "      <td>Modi ho ya Manmohan singh saala yeh log kuch n...</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ID  \\\n",
       "0  facebook_corpus_msr_451811   \n",
       "1  facebook_corpus_msr_334368   \n",
       "2  facebook_corpus_msr_331195   \n",
       "3  facebook_corpus_msr_403402   \n",
       "4  facebook_corpus_msr_379239   \n",
       "\n",
       "                                             Comment Label  \n",
       "0  The quality of re made now makes me think it i...   CAG  \n",
       "1  @siva \\rHow is ur mother???\\rHow is ur wife???...   NAG  \n",
       "2  Also see ....hw ur RSS activist caught in Burk...   NAG  \n",
       "3  On the death of 2 jawans in LOC CROSS FIRING\\r...   NAG  \n",
       "4  Modi ho ya Manmohan singh saala yeh log kuch n...   OAG  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdevraw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook_corpus_msr_1723796</td>\n",
       "      <td>Well said sonu..you have courage to stand agai...</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook_corpus_msr_466073</td>\n",
       "      <td>Most of Private Banks ATM's Like HDFC, ICICI e...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook_corpus_msr_1493901</td>\n",
       "      <td>Now question is, Pakistan will adhere to this?</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook_corpus_msr_405512</td>\n",
       "      <td>Pakistan is comprised of fake muslims who does...</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook_corpus_msr_1521685</td>\n",
       "      <td>??we r against cow slaughter,so of course it w...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ID  \\\n",
       "0  facebook_corpus_msr_1723796   \n",
       "1   facebook_corpus_msr_466073   \n",
       "2  facebook_corpus_msr_1493901   \n",
       "3   facebook_corpus_msr_405512   \n",
       "4  facebook_corpus_msr_1521685   \n",
       "\n",
       "                                             Comment Label  \n",
       "0  Well said sonu..you have courage to stand agai...   OAG  \n",
       "1  Most of Private Banks ATM's Like HDFC, ICICI e...   NAG  \n",
       "2     Now question is, Pakistan will adhere to this?   OAG  \n",
       "3  Pakistan is comprised of fake muslims who does...   OAG  \n",
       "4  ??we r against cow slaughter,so of course it w...   NAG  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrainraw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(texts):\n",
    "    cleaned_text = []\n",
    "    for text in texts:\n",
    "        # remove ugly &quot and &amp\n",
    "        text = re.sub(r'&quot;(.*?)&quot;', \"\\g<1>\", text)\n",
    "        text = re.sub(r'&amp;', \"\", text)\n",
    "\n",
    "        # replace emoticon\n",
    "        text = re.sub(r'(^| )(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)', \"\\g<1>TOKEMOTICON\", text)\n",
    "\n",
    "        text = text.lower()\n",
    "        text = text.replace(\"tokemoticon\", \"TOKEMOTICON\")\n",
    "\n",
    "        # replace url\n",
    "        text = re.sub(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?',\n",
    "                    \"TOKURL\", text)\n",
    "\n",
    "        # replace mention\n",
    "        text = re.sub(r'@[\\w]+', \"TOKMENTION\", text)\n",
    "\n",
    "        # replace hashtag\n",
    "        text = re.sub(r'#[\\w]+', \"TOKHASHTAG\", text)\n",
    "\n",
    "        # replace dollar\n",
    "        text = re.sub(r'\\$\\d+', \"TOKDOLLAR\", text)\n",
    "\n",
    "        # remove punctuation\n",
    "        text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "\n",
    "        # remove multiple spaces\n",
    "        text = re.sub(r' +', ' ', text)\n",
    "\n",
    "        # remove newline\n",
    "        text = re.sub(r'\\n', ' ', text)\n",
    "\n",
    "        cleaned_text.append(text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def removeurl(string):\n",
    "#    return re.sub(r'^http[s]?:\\/\\/.*[\\r\\n]*', '', string, flags=re.MULTILINE)\n",
    "\n",
    "class2index = {'OAG':2,'CAG':0,'NAG':1}\n",
    "index2class = {2:'OAG',0:'CAG',1:'NAG'}\n",
    "\n",
    "\n",
    "def removeurl(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    #return re.sub(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+] |[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"\", sample.lower())\n",
    "    return re.sub(r\"http\\S+\", \"\", sample)\n",
    "\n",
    "def removenonascii(post):\n",
    "    printable = set(string.printable)\n",
    "    return ''.join(filter(lambda x: x in printable, post))\n",
    "\n",
    "def removenewline(string):\n",
    "    string = string.replace('\\r', ' ')\n",
    "    string = string.replace('\\n', ' ')\n",
    "    return string    \n",
    "\n",
    "def removepunctuation(string):\n",
    "    return ''.join([c for c in string if c not in punctuation])\n",
    "\n",
    "def removepunctuationwithspace(string):\n",
    "    string = re.sub(r'[^\\w\\s]',' ',string)\n",
    "    return string\n",
    "\n",
    "def removepunctuationandnumbers(string):\n",
    "    string = re.sub('[^a-zA-Z]', ' ', string)\n",
    "    return string\n",
    "\n",
    "\n",
    "def stemwords(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatizeverbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def rawprocess(df):\n",
    "    result = pd.DataFrame(df)\n",
    "    countpunctuation = []\n",
    "    countexclamation = []\n",
    "    \n",
    "    for index, row in result.iterrows():\n",
    "        countpunctuation.append(len([c for c in row['Comment'] if c in punctuation]))\n",
    "        countexclamation.append(len([c for c in row['Comment'] if c in ['!','?']]))\n",
    "    result['countpunctuation'] = countpunctuation \n",
    "    result['countexclamation'] = countexclamation    \n",
    "    return result    \n",
    "  \n",
    "\n",
    "\n",
    "\"\"\"def preprocess_old(df):\n",
    "    result = pd.DataFrame(df)\n",
    "    labelnumber = []\n",
    "    for index, row in result.iterrows():\n",
    "        #print(row['c1'], row['c2'])\n",
    "        row['Comment'] = removepunctuation(removenewline(removenonascii(emoji.demojize(removeurl(row['Comment']))))).lower()\n",
    "        labelnumber.append(class2index[row['Label']])\n",
    "        #if(row['Comment']==''):\n",
    "        #    print(row['ID']   \n",
    "    result['labelnumber'] = labelnumber    \n",
    "    return result\"\"\"    \n",
    "\n",
    "def preprocess(df, haslabel=True):\n",
    "    result = pd.DataFrame(df)\n",
    "    labelnumber = []\n",
    "    commentnotlowered = []\n",
    "    for index, row in result.iterrows():\n",
    "        #print(row['c1'], row['c2'])\n",
    "        \n",
    "        row['Comment'] = contractions.fix(row['Comment'])\n",
    "        comment = removepunctuationandnumbers(removenewline(removenonascii(emoji.demojize(removeurl(row['Comment'])))))\n",
    "        commentnotlowered.append(comment)\n",
    "        row['Comment'] = comment.lower()\n",
    "        if haslabel:\n",
    "            labelnumber.append(class2index[row['Label']])\n",
    "        #if(row['Comment']==''):\n",
    "        #    print(row['ID']   \n",
    "    if haslabel:\n",
    "        result['labelnumber'] = labelnumber    \n",
    "    result['commentnotlowered'] = commentnotlowered\n",
    "    return result\n",
    "\n",
    "\n",
    "def tokenization_old(df):\n",
    "    alltokens = []\n",
    "    tokenizer = TweetTokenizer()\n",
    "    for index, row in df.iterrows():\n",
    "        commenttokens = tokenizer.tokenize(row['Comment'])\n",
    "        alltokens.append(commenttokens)\n",
    "        \n",
    "    df['tokens'] = alltokens    \n",
    "    return df\n",
    "\n",
    "\n",
    "def tokenization(df):\n",
    "    result = pd.DataFrame(df)\n",
    "    alltokens = []\n",
    "    alltokensnotlowered = []\n",
    "    tokenizer = TweetTokenizer()\n",
    "    for index, row in df.iterrows():\n",
    "        commenttokens = tokenizer.tokenize(row['commentnotlowered'])\n",
    "        \n",
    "        alltokensnotlowered.append(commenttokens)\n",
    "        alltokens.append([x.lower() for x in commenttokens])\n",
    "        \n",
    "    result['tokens'] = alltokens \n",
    "    result['tokensnotlowered'] = alltokensnotlowered \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = preprocess(dftrainraw)\n",
    "dfdev = preprocess(dfdevraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "dfdev = tokenization(dfdev)\n",
    "dftrain  = tokenization(dftrain)\n",
    "train_tokens = [row['tokens'] for index,row in dftrain.iterrows()]\n",
    "dev_tokens = [row['tokens'] for index,row in dfdev.iterrows()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "      <th>labelnumber</th>\n",
       "      <th>commentnotlowered</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokensnotlowered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook_corpus_msr_1723796</td>\n",
       "      <td>well said sonu  you have courage to stand agai...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>2</td>\n",
       "      <td>well said sonu  you have courage to stand agai...</td>\n",
       "      <td>[well, said, sonu, you, have, courage, to, sta...</td>\n",
       "      <td>[Well, said, sonu, you, have, courage, to, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook_corpus_msr_466073</td>\n",
       "      <td>most of private banks atm s like hdfc  icici e...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>1</td>\n",
       "      <td>most of private banks atm s like hdfc  icici e...</td>\n",
       "      <td>[most, of, private, banks, atm, s, like, hdfc,...</td>\n",
       "      <td>[Most, of, Private, Banks, ATM, s, Like, HDFC,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook_corpus_msr_1493901</td>\n",
       "      <td>now question is  pakistan will adhere to this</td>\n",
       "      <td>OAG</td>\n",
       "      <td>2</td>\n",
       "      <td>now question is  pakistan will adhere to this</td>\n",
       "      <td>[now, question, is, pakistan, will, adhere, to...</td>\n",
       "      <td>[Now, question, is, Pakistan, will, adhere, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook_corpus_msr_405512</td>\n",
       "      <td>pakistan is comprised of fake muslims who does...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>2</td>\n",
       "      <td>pakistan is comprised of fake muslims who does...</td>\n",
       "      <td>[pakistan, is, comprised, of, fake, muslims, w...</td>\n",
       "      <td>[Pakistan, is, comprised, of, fake, muslims, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook_corpus_msr_1521685</td>\n",
       "      <td>we r against cow slaughter so of course it w...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>1</td>\n",
       "      <td>we r against cow slaughter so of course it w...</td>\n",
       "      <td>[we, r, against, cow, slaughter, so, of, cours...</td>\n",
       "      <td>[we, r, against, cow, slaughter, so, of, cours...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ID  \\\n",
       "0  facebook_corpus_msr_1723796   \n",
       "1   facebook_corpus_msr_466073   \n",
       "2  facebook_corpus_msr_1493901   \n",
       "3   facebook_corpus_msr_405512   \n",
       "4  facebook_corpus_msr_1521685   \n",
       "\n",
       "                                             Comment Label  labelnumber  \\\n",
       "0  well said sonu  you have courage to stand agai...   OAG            2   \n",
       "1  most of private banks atm s like hdfc  icici e...   NAG            1   \n",
       "2     now question is  pakistan will adhere to this    OAG            2   \n",
       "3  pakistan is comprised of fake muslims who does...   OAG            2   \n",
       "4    we r against cow slaughter so of course it w...   NAG            1   \n",
       "\n",
       "                                   commentnotlowered  \\\n",
       "0  well said sonu  you have courage to stand agai...   \n",
       "1  most of private banks atm s like hdfc  icici e...   \n",
       "2     now question is  pakistan will adhere to this    \n",
       "3  pakistan is comprised of fake muslims who does...   \n",
       "4    we r against cow slaughter so of course it w...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [well, said, sonu, you, have, courage, to, sta...   \n",
       "1  [most, of, private, banks, atm, s, like, hdfc,...   \n",
       "2  [now, question, is, pakistan, will, adhere, to...   \n",
       "3  [pakistan, is, comprised, of, fake, muslims, w...   \n",
       "4  [we, r, against, cow, slaughter, so, of, cours...   \n",
       "\n",
       "                                    tokensnotlowered  \n",
       "0  [Well, said, sonu, you, have, courage, to, sta...  \n",
       "1  [Most, of, Private, Banks, ATM, s, Like, HDFC,...  \n",
       "2  [Now, question, is, Pakistan, will, adhere, to...  \n",
       "3  [Pakistan, is, comprised, of, fake, muslims, w...  \n",
       "4  [we, r, against, cow, slaughter, so, of, cours...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'quality',\n",
       "  'of',\n",
       "  're',\n",
       "  'made',\n",
       "  'now',\n",
       "  'makes',\n",
       "  'me',\n",
       "  'think',\n",
       "  'it',\n",
       "  'is',\n",
       "  'something',\n",
       "  'to',\n",
       "  'be',\n",
       "  'bought',\n",
       "  'from',\n",
       "  'fish',\n",
       "  'market'],\n",
       " ['siva',\n",
       "  'how',\n",
       "  'is',\n",
       "  'ur',\n",
       "  'mother',\n",
       "  'how',\n",
       "  'is',\n",
       "  'ur',\n",
       "  'wife',\n",
       "  'how',\n",
       "  'is',\n",
       "  'ur',\n",
       "  'sister',\n",
       "  'hope',\n",
       "  'everyone',\n",
       "  'is',\n",
       "  'fine'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdev['tokens'][0],dfdev['tokens'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "      <th>labelnumber</th>\n",
       "      <th>commentnotlowered</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokensnotlowered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook_corpus_msr_451811</td>\n",
       "      <td>the quality of re made now makes me think it i...</td>\n",
       "      <td>CAG</td>\n",
       "      <td>0</td>\n",
       "      <td>The quality of re made now makes me think it i...</td>\n",
       "      <td>[the, quality, of, re, made, now, makes, me, t...</td>\n",
       "      <td>[The, quality, of, re, made, now, makes, me, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook_corpus_msr_334368</td>\n",
       "      <td>siva  how is ur mother    how is ur wife    h...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>1</td>\n",
       "      <td>siva  How is ur mother    How is ur wife    H...</td>\n",
       "      <td>[siva, how, is, ur, mother, how, is, ur, wife,...</td>\n",
       "      <td>[siva, How, is, ur, mother, How, is, ur, wife,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook_corpus_msr_331195</td>\n",
       "      <td>also see     hw ur rss activist caught in burk...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>1</td>\n",
       "      <td>Also see     hw ur RSS activist caught in Burk...</td>\n",
       "      <td>[also, see, hw, ur, rss, activist, caught, in,...</td>\n",
       "      <td>[Also, see, hw, ur, RSS, activist, caught, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook_corpus_msr_403402</td>\n",
       "      <td>on the death of 2 jawans in loc cross firing  ...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>1</td>\n",
       "      <td>On the death of 2 jawans in LOC CROSS FIRING  ...</td>\n",
       "      <td>[on, the, death, of, 2, jawans, in, loc, cross...</td>\n",
       "      <td>[On, the, death, of, 2, jawans, in, LOC, CROSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook_corpus_msr_379239</td>\n",
       "      <td>modi ho ya manmohan singh saala yeh log kuch n...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>2</td>\n",
       "      <td>Modi ho ya Manmohan singh saala yeh log kuch n...</td>\n",
       "      <td>[modi, ho, ya, manmohan, singh, saala, yeh, lo...</td>\n",
       "      <td>[Modi, ho, ya, Manmohan, singh, saala, yeh, lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ID  \\\n",
       "0  facebook_corpus_msr_451811   \n",
       "1  facebook_corpus_msr_334368   \n",
       "2  facebook_corpus_msr_331195   \n",
       "3  facebook_corpus_msr_403402   \n",
       "4  facebook_corpus_msr_379239   \n",
       "\n",
       "                                             Comment Label  labelnumber  \\\n",
       "0  the quality of re made now makes me think it i...   CAG            0   \n",
       "1   siva  how is ur mother    how is ur wife    h...   NAG            1   \n",
       "2  also see     hw ur rss activist caught in burk...   NAG            1   \n",
       "3  on the death of 2 jawans in loc cross firing  ...   NAG            1   \n",
       "4  modi ho ya manmohan singh saala yeh log kuch n...   OAG            2   \n",
       "\n",
       "                                   commentnotlowered  \\\n",
       "0  The quality of re made now makes me think it i...   \n",
       "1   siva  How is ur mother    How is ur wife    H...   \n",
       "2  Also see     hw ur RSS activist caught in Burk...   \n",
       "3  On the death of 2 jawans in LOC CROSS FIRING  ...   \n",
       "4  Modi ho ya Manmohan singh saala yeh log kuch n...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [the, quality, of, re, made, now, makes, me, t...   \n",
       "1  [siva, how, is, ur, mother, how, is, ur, wife,...   \n",
       "2  [also, see, hw, ur, rss, activist, caught, in,...   \n",
       "3  [on, the, death, of, 2, jawans, in, loc, cross...   \n",
       "4  [modi, ho, ya, manmohan, singh, saala, yeh, lo...   \n",
       "\n",
       "                                    tokensnotlowered  \n",
       "0  [The, quality, of, re, made, now, makes, me, t...  \n",
       "1  [siva, How, is, ur, mother, How, is, ur, wife,...  \n",
       "2  [Also, see, hw, ur, RSS, activist, caught, in,...  \n",
       "3  [On, the, death, of, 2, jawans, in, LOC, CROSS...  \n",
       "4  [Modi, ho, ya, Manmohan, singh, saala, yeh, lo...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdev.to_pickle('dev_tokenized_df.pkl')\n",
    "dftrain.to_pickle('train_tokenized_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 22138\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of tokens\n",
    "vocabulary = set([t for tokens in train_tokens + dev_tokens for t in tokens])\n",
    "print('Vocabulary size: {}'.format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('vocabulary.pkl', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(vocabulary, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftestraw =  pd.read_csv(\"data/test_no_label.csv\", encoding='latin') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = preprocess(dftestraw, False)\n",
    "dftest  = tokenization(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>commentnotlowered</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokensnotlowered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook_corpus_msr_495558</td>\n",
       "      <td>but if same had been given before olymic games...</td>\n",
       "      <td>But if same had been given before olymic games...</td>\n",
       "      <td>[but, if, same, had, been, given, before, olym...</td>\n",
       "      <td>[But, if, same, had, been, given, before, olym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook_corpus_msr_1561809</td>\n",
       "      <td>does our constitution gives power to misbehave...</td>\n",
       "      <td>Does our constitution gives power to misbehave...</td>\n",
       "      <td>[does, our, constitution, gives, power, to, mi...</td>\n",
       "      <td>[Does, our, constitution, gives, power, to, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook_corpus_msr_442487</td>\n",
       "      <td>automotive awards are done at the cost of spar...</td>\n",
       "      <td>automotive awards are done at the cost of spar...</td>\n",
       "      <td>[automotive, awards, are, done, at, the, cost,...</td>\n",
       "      <td>[automotive, awards, are, done, at, the, cost,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook_corpus_msr_495517</td>\n",
       "      <td>i appreciate the stated facts but the last one...</td>\n",
       "      <td>I appreciate the stated facts but the last one...</td>\n",
       "      <td>[i, appreciate, the, stated, facts, but, the, ...</td>\n",
       "      <td>[I, appreciate, the, stated, facts, but, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook_corpus_msr_1805455</td>\n",
       "      <td>rss agent mr hazare how you are feeling now</td>\n",
       "      <td>RSS agent Mr Hazare how you are feeling now</td>\n",
       "      <td>[rss, agent, mr, hazare, how, you, are, feelin...</td>\n",
       "      <td>[RSS, agent, Mr, Hazare, how, you, are, feelin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ID  \\\n",
       "0   facebook_corpus_msr_495558   \n",
       "1  facebook_corpus_msr_1561809   \n",
       "2   facebook_corpus_msr_442487   \n",
       "3   facebook_corpus_msr_495517   \n",
       "4  facebook_corpus_msr_1805455   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  but if same had been given before olymic games...   \n",
       "1  does our constitution gives power to misbehave...   \n",
       "2  automotive awards are done at the cost of spar...   \n",
       "3  i appreciate the stated facts but the last one...   \n",
       "4       rss agent mr hazare how you are feeling now    \n",
       "\n",
       "                                   commentnotlowered  \\\n",
       "0  But if same had been given before olymic games...   \n",
       "1  Does our constitution gives power to misbehave...   \n",
       "2  automotive awards are done at the cost of spar...   \n",
       "3  I appreciate the stated facts but the last one...   \n",
       "4       RSS agent Mr Hazare how you are feeling now    \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [but, if, same, had, been, given, before, olym...   \n",
       "1  [does, our, constitution, gives, power, to, mi...   \n",
       "2  [automotive, awards, are, done, at, the, cost,...   \n",
       "3  [i, appreciate, the, stated, facts, but, the, ...   \n",
       "4  [rss, agent, mr, hazare, how, you, are, feelin...   \n",
       "\n",
       "                                    tokensnotlowered  \n",
       "0  [But, if, same, had, been, given, before, olym...  \n",
       "1  [Does, our, constitution, gives, power, to, mi...  \n",
       "2  [automotive, awards, are, done, at, the, cost,...  \n",
       "3  [I, appreciate, the, stated, facts, but, the, ...  \n",
       "4  [RSS, agent, Mr, Hazare, how, you, are, feelin...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest.to_pickle('test_tokenized_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVpqEKiQjRCf"
   },
   "source": [
    "**Word Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YodY1Tg6jPZP"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class WordEmbedder(nn.Module):\n",
    "    def __init__(self, vocab, glove_file, seqlen = 300, varlen = False):\n",
    "        super(WordEmbedder, self).__init__()\n",
    "        assert os.path.exists(glove_file) and glove_file.endswith('.txt'), glove_file\n",
    "        \n",
    "        self.emb_dim = None\n",
    "        \n",
    "        self.PAD_TOKEN = '<PAD>'\n",
    "        self.UNK_TOKEN = '<UNK>'\n",
    "        self.sequence_length = seqlen\n",
    "        self.various_length = varlen\n",
    "        \n",
    "        idx2word = [self.PAD_TOKEN, self.UNK_TOKEN]\n",
    "        idx2vect = [None, None]\n",
    "        \n",
    "        with open(glove_file, 'r', encoding='utf-8') as fp:\n",
    "            for line in fp:\n",
    "                line = line.split()\n",
    "                \n",
    "                if line[0] not in vocab:\n",
    "                    continue\n",
    "                \n",
    "                w = line[0]\n",
    "                v = np.array([float(value) for value in line[1:]])\n",
    "                \n",
    "                if self.emb_dim is None:\n",
    "                    self.emb_dim = v.shape[0]\n",
    "            \n",
    "                idx2word.append(w)\n",
    "                idx2vect.append(v)\n",
    "                \n",
    "        idx2vect[0] = np.zeros(self.emb_dim)\n",
    "        idx2vect[1] = np.mean(idx2vect[2:], axis=0)\n",
    "    \n",
    "        self.embeddings = torch.from_numpy(np.array(idx2vect)).float()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(self.embeddings, freeze=False)\n",
    "        \n",
    "        self.idx2word = {i: w for i, w in enumerate(idx2word)}\n",
    "        self.word2idx = {w: i for i, w in self.idx2word.items()}\n",
    "    \n",
    "    def forward(self, samples):\n",
    "        pad_idx = self.word2idx[self.PAD_TOKEN]\n",
    "        unk_idx = self.word2idx[self.UNK_TOKEN]\n",
    "        \n",
    "        if self.various_length:\n",
    "\n",
    "            #Find the length of the longest sample\n",
    "            maxlen = max([len(s) for s in samples])\n",
    "        \n",
    "        else:\n",
    "\n",
    "            #Use a constant length for all samples\n",
    "            maxlen = self.sequence_length\n",
    "        \n",
    "        encoded = [[self.word2idx.get(token, unk_idx) for token in tokens] for tokens in samples]\n",
    "        \n",
    "        padded = np.zeros((len(samples), maxlen), dtype=int)\n",
    "        masks = torch.zeros(len(samples), maxlen).long()\n",
    "        \n",
    "        # Padding and masking\n",
    "        for i in range(len(encoded)):\n",
    "            masks[i, :len(encoded[i])] = 1\n",
    "            padded[i, :len(encoded[i])] = np.array(encoded[i])[:maxlen]\n",
    "            # encoded[i] += [pad_idx] * max(0, (maxlen - len(encoded[i])))\n",
    "        \n",
    "        encoded = torch.tensor(padded).long()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            encoded = encoded.cuda()\n",
    "            masks = masks.cuda()\n",
    "        \n",
    "        result = {\n",
    "            'output': self.embeddings(encoded),\n",
    "            'mask': masks,\n",
    "            'encoded': encoded\n",
    "        }\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabulary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-87fe4beb1e4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0membedder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordEmbedder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglove_folder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'glove.42B.300d.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0membedder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocabulary' is not defined"
     ]
    }
   ],
   "source": [
    "embedder = WordEmbedder(vocabulary, glove_folder+'glove.42B.300d.txt', varlen=True)\n",
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type WordEmbedder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(embedder,'embedder_glove.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hand-crafted Features - Comment level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handcraftedfeatures(df):\n",
    "    pf= ProfanityFilter()\n",
    "    \n",
    "    result = pd.DataFrame(df)\n",
    "    \n",
    "    negativetokencount = []\n",
    "    titletokencount = []\n",
    "    allcaptokencount = []\n",
    "    \n",
    "    for index,row in result.iterrows():\n",
    "        commenttokens = row['tokensnotlowered']\n",
    "        #print(row['commentnotlowered'])\n",
    "        negativecount =0\n",
    "        titlecount = 0\n",
    "        allcapcount = 0\n",
    "        \n",
    "        for token in commenttokens:\n",
    "           # print(token,end='')\n",
    "            if token.istitle():\n",
    "            #    print(\" \"+str(titlecount),end='')\n",
    "                titlecount=titlecount+1\n",
    "            #    print(\" title (\"+str(titlecount)+\")\",end='')\n",
    "            if token.isupper():\n",
    "                allcapcount+=1\n",
    "            if not pf.is_clean(token.lower()):\n",
    "                negativecount+=1\n",
    "            #print(\"\")\n",
    "                \n",
    "        negativetokencount.append(negativecount)\n",
    "        titletokencount.append(titlecount)\n",
    "        allcaptokencount.append(allcapcount)\n",
    "        \n",
    "        if(index%100==0):\n",
    "            print(\"Completed\",index)\n",
    " \n",
    "    result['negativetokencount'] = negativetokencount  \n",
    "    result['titletokencount'] = titletokencount\n",
    "    result['allcaptokencount'] = allcaptokencount\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def handcraftedfeatures2(df):\n",
    "    en_dict = enchant.Dict(\"en_US\")\n",
    "    \n",
    "    result = pd.DataFrame(df)\n",
    "    \n",
    "    totaltokencount = []\n",
    "    nonenglishtokencount = []\n",
    "    \n",
    "    \n",
    "    for index,row in result.iterrows():\n",
    "        commenttokens = row['tokens']\n",
    "        #print(row['commentnotlowered'])\n",
    "        totaltokens = len(commenttokens)\n",
    "        \n",
    "        nonenglishtokens = sum([ 0 if en_dict.check(token) else 1 for token in commenttokens])\n",
    "           \n",
    "                \n",
    "        totaltokencount.append(totaltokens)\n",
    "        nonenglishtokencount.append(nonenglishtokens)\n",
    "        \n",
    "        if(index%100==0):\n",
    "            print(\"Completed\",index)\n",
    " \n",
    "    result['totaltokencount'] = totaltokencount  \n",
    "    result['nonenglishtokencount'] = nonenglishtokencount\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "handtrain = handcraftedfeatures(dftrain)\n",
    "handtrain = handcraftedfeatures2(handtrain)\n",
    "end = time.time()\n",
    "print(\"train completed\",time.strftime(\"%H:%M:%S\", time.gmtime(end-start)))\n",
    "handtrain.to_pickle('train_tokenized_handfeat_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "handdev = handcraftedfeatures(dfdev)\n",
    "handdev = handcraftedfeatures2(handdev)\n",
    "end = time.time()\n",
    "print(\"dev completed\",time.strftime(\"%H:%M:%S\", time.gmtime(end-start)))\n",
    "handdev.to_pickle('dev_tokenized_handfeat_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hand-crafted features - Word level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handfeatureextract(samples, sequence_length=300,various_length=True):\n",
    "    \n",
    "\n",
    "    maxlen = 0\n",
    "    \n",
    "    if various_length:\n",
    "        #Find the length of the longest sample\n",
    "        #maxlen = max([len(row['tokensnotlowered']) for index,row in df.iterrows()])\n",
    "        maxlen = max([len(s) for s in samples])\n",
    "    else:\n",
    "        #Use a constant length for all samples\n",
    "        maxlen = sequence_length\n",
    "    \n",
    "    basicfeatures = []\n",
    "    for tokens in samples:\n",
    "        #comment = row['commentnotlowered']\n",
    "        \n",
    "        taggedtokens = nltk.pos_tag(' '.join(tokens))\n",
    "        \n",
    "        #print(tokens, taggedtokens)\n",
    "        commentbasicfeatures = addfeatures(tokens, taggedtokens, maxlen)\n",
    "        \n",
    "        #print(len(commentbasicfeatures))\n",
    "        \n",
    "        basicfeatures.append(commentbasicfeatures)\n",
    "        \n",
    "        handfeatures = [[[word[key] for key in word] for word in handfeature] for handfeature in basicfeatures]\n",
    "    \n",
    "    return handfeatures\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
